{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n2Lvvt9SZBTi"
      },
      "source": [
        "# COLLAB DE MODELISATION\n",
        "\n",
        "## Avant de commencer, modifier les constances de la première cellule\n",
        "\n",
        "*   Avoir créé branche neuve depuis le master et pousser tout le code sur votre Drive\n",
        "*   Créer des modèles texte, image et/ou fusion dans les fichiers \n",
        "  * Ecrire vos modèles dans ```src/models/models_text.py```, ```src/models/models_image.py``` et/ou ```src/models/models_fusion.py```\n",
        "  * Ajouter-les dans `build_pipeline_model` dans `image.py`, `text.py` et/ou `fusion.py`\n",
        "  * Modifier `MODEL_TEXT_NAME`, `MODEL_IMAGE_NAME` et/ou `MODEL_FUSION_NAME`\n",
        "*   Modifier le chemin d'accès `PATH_PROJECT` vers votre dossier du projet à vous\n",
        "*   Avoir les photos en `500x500`\n",
        "  * Créer un fichier `.zip` sur votre ordi et y mettre toutes les photos du dossier ```images/image_train```\n",
        "  * Uploader ce fichier sur votre Drive\n",
        "  * Adapter ```LIEN_VERS_ZIP``` de la cellule ```shutil.unpack_archive```\n",
        "  * Mettre la constante ```UNZIP``` à True\n",
        "  * Vérifier que les photos sont bien dans ```xxx/data/raw/images/image_train```\n",
        "* Exécuter tout code suivant\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KZJAOrAMmCGB"
      },
      "outputs": [],
      "source": [
        "while True:pass"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zI5UcsCQOsSd"
      },
      "outputs": [],
      "source": [
        "PATH_PROJECT = \"/content/drive/MyDrive/DS-rakuten/Rakuten\"\n",
        "\n",
        "MODEL_TEXT_NAME = \"nn_simple\"\n",
        "MODEL_IMAGE_NAME = \"vgg16_transfer_learning\"\n",
        "MODEL_FUSION_NAME = \"fusion_simple\"\n",
        "\n",
        "UNZIP = False #Pour dezipper les fichiers\n",
        "CHECK_IMAGES = False # Pour verifier que tout le monde ait bien le bon nmbre d'images\n",
        "\n",
        "TRAIN_IMAGE = True #Pour entrainer le modele d'image MODEL_IMAGE_NAME\n",
        "TRAIN_TEXT = False #Pour entrainer le modele d'image MODEL_TEXT_NAME\n",
        "TRAIN_FUSION = False #Pour entrainer le modele d'image MODEL_FUSION_NAME\n",
        "\n",
        "BATCH_SIZE = 64\n",
        "EPOCHS_IMAGE = 50\n",
        "EPOCHS_TEXT = 5\n",
        "TARGET_SHAPE = (56, 56, 3) #Taille néssaire pour VGG16\n",
        "\n",
        "PATH_MODELS = \"/content/drive/MyDrive/DS-rakuten/\""
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JwKI-TljRMXU"
      },
      "source": [
        "## CODE\n",
        "### Mise en place"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RoSCi54aBWrV"
      },
      "outputs": [],
      "source": [
        "# Chargement du dashboard TensorBoard\n",
        "%reload_ext tensorboard"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KHhDyEYIowmu"
      },
      "outputs": [],
      "source": [
        "# Ajout de Drive au syspath\n",
        "from google.colab import drive\n",
        "import sys\n",
        "\n",
        "drive.mount('/content/drive', force_remount=True)\n",
        "sys.path.insert(0, PATH_PROJECT)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tv9fFiE4Y5aP"
      },
      "outputs": [],
      "source": [
        "# Ajout d'imports specifiques pour collab\n",
        "!pip install unidecode\n",
        "!pip install fasttext\n",
        "!pip install googletrans\n",
        "\n",
        "#Import des sources\n",
        "from main import text_tools, image_tools, commons, graphs, model_tools, model_fusion, Path\n",
        "import datetime\n",
        "import os\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from imblearn.metrics import classification_report_imbalanced\n",
        "import joblib\n",
        "import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "PATH_RAW = Path(PATH_PROJECT, \"data/raw\")\n",
        "PATH_BASE = Path(PATH_PROJECT, \"data/base\")\n",
        "PATH_FEAT = Path(PATH_PROJECT, \"data/featured\")\n",
        "PATH_TRANS = Path(PATH_PROJECT, \"data/translated\")\n",
        "PATH_MODELS = Path(PATH_PROJECT, \"src/models\")\n",
        "\n",
        "LOG_DIR_TEXT = Path(PATH_PROJECT, \"logs/text\", MODEL_TEXT_NAME, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
        "LOG_DIR_IMAGE = Path(PATH_PROJECT, \"logs/image\",MODEL_IMAGE_NAME, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))\n",
        "LOG_DIR_FUSION = Path(PATH_PROJECT, \"logs/fusion\",MODEL_FUSION_NAME, datetime.datetime.now().strftime('%Y%m%d-%H%M%S'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bBSXt3tNUthE"
      },
      "outputs": [],
      "source": [
        "#Dezippage des photos si necessaire\n",
        "PATH_IMAGES_TRAIN = str(Path(PATH_RAW, \"images/image_train\"))\n",
        "if UNZIP:\n",
        "  import shutil \n",
        "\n",
        "  LIEN_VERS_ZIP = '/content/drive/Rakuten/Telechargement/test.zip'\n",
        "  shutil.unpack_archive(LIEN_VERS_ZIP, PATH_IMAGES_TRAIN)\n",
        "\n",
        "if CHECK_IMAGES:\n",
        "  import os\n",
        "  _, _, files = next(os.walk(PATH_IMAGES_TRAIN))\n",
        "  file_count = len(files)\n",
        "  assert file_count == 84916, f\"ATTENTION, il manque des images sur les 84916 images requises, ou alors elles ne sont pas dans le bon dossier : les deplacer dans le dossier {PATH_IMAGES_TRAIN}\"\n",
        "  print(f\"{file_count} dans votre dossier {PATH_IMAGES_TRAIN}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rrpxlCpYng4q"
      },
      "outputs": [],
      "source": [
        "# functions\n",
        "def create_balanced_subset(df, samples_per_class, targetcol='target', savepath=None):\n",
        "    \"\"\"\n",
        "    Extracts a balanced subset from given DataFrame by random downsampling each\n",
        "    class to fixed specified number of observations\n",
        "    \"\"\"\n",
        "    # Check\n",
        "    condition = samples_per_class < df[targetcol].value_counts().min()\n",
        "    error_msg = f\"Number {samples_per_class} exceeds cardinal of smallest class\"\n",
        "    assert condition, error_msg\n",
        "    # Go through all modalities\n",
        "    idxs = [] # list of indexes to select\n",
        "    for label in list(df[targetcol].unique()):\n",
        "        # Indexes matching label\n",
        "        idxs_label = list(df[df[targetcol] == label].index)\n",
        "        # Sample random specimens\n",
        "        np.random.shuffle(idxs_label)\n",
        "        idxs_rand = idxs_label[:samples_per_class]\n",
        "        # Add to list\n",
        "        idxs += idxs_rand\n",
        "    # Extract rows\n",
        "    df = df.loc[df.index.intersection(idxs)]\n",
        "    print(\"Balanced subset successfully created\")\n",
        "    if savepath:\n",
        "        # Save subset\n",
        "        df.to_csv(savepath, index=True, header=True)\n",
        "        print(f\"Dataframe saved to: '{savepath}'\")\n",
        "    return df"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8dPbuq4H7bQU"
      },
      "source": [
        "### Calculs\n",
        "\n",
        "#### Preprocess"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tfzX9C8wZm1v"
      },
      "outputs": [],
      "source": [
        "# Read and transform dataset \n",
        "\n",
        "\n",
        "# #Chargement des targets\n",
        "# df_y = text_tools.read_csv(name=\"Y_train_CVw08PX.csv\", folder=PATH_RAW)\n",
        "# NB_SAMPLES = 5000\n",
        "# #Chargement des données textuelles\n",
        "# df_text = text_tools.read_csv(name=\"X_train_update.csv\", folder=PATH_RAW)\n",
        "# #df_y = df_y.loc[df_text.index]\n",
        "# df_full = df_text.join(df_y)\n",
        "# df_full.head()\n",
        "\n",
        "# samples_per_class = 500\n",
        "# print(\"samples_per_class\", samples_per_class)\n",
        "# df_balanced = create_balanced_subset(df_full, samples_per_class, targetcol='prdtypecode')\n",
        "# df_balanced.head()\n",
        "\n",
        "# df_y = df_balanced['prdtypecode']\n",
        "# df_text = df_balanced.drop('prdtypecode', axis=1)\n",
        "\n",
        "# len(df_text)\n",
        "\n",
        "# #Application du pipeline de chargement\n",
        "# pipeline_loader = text_tools.build_pipeline_load(path=str(PATH_RAW))\n",
        "# df_text = pipeline_loader.fit_transform(df_text)\n",
        "\n",
        "# #Transformations : recherche de la langue et traduction\n",
        "# pipeline_lang = text_tools.build_pipeline_lang(translate=False)    #TODO régler le pb avec l'API de trad\n",
        "# df_text = pipeline_lang.fit_transform(df_text)\n",
        "# commons.save_pkl(df_text, name=\"df_text.pkl\", folder=PATH_TRANS)\n",
        "\n",
        "\n",
        "# Import training and testing data + rename label column\n",
        "X_train = pd.read_csv(Path(PATH_RAW, './X_train_update.csv'), index_col=0)\n",
        "y_train = pd.read_csv(Path(PATH_RAW, './Y_train_CVw08PX.csv'), index_col=0)\n",
        "y_train = y_train.rename(columns={\"prdtypecode\": \"label\"})\n",
        "\n",
        "#X_test = pd.read_csv(Path(PATH_RAW,'./X_test_update.csv'), index_col=0)\n",
        "\n",
        "# Remove unecessary columns and create image id ['img_id']\n",
        "X_train['filename'] = 'image_'+ X_train['imageid'].astype(str) + '_product_' + X_train['productid'].astype(str) + '.jpg'\n",
        "del X_train['designation'], X_train['description'], X_train['productid'], X_train['imageid']\n",
        "\n",
        "# X_test['filename'] = 'image_'+ X_test['imageid'].astype(str) + '_product_' + X_test['productid'].astype(str) + '.jpg'\n",
        "# del X_test['designation'], X_test['description'], X_test['productid'], X_test['imageid']\n",
        "\n",
        "print(X_train.shape)\n",
        "print(y_train.shape)\n",
        "# print(X_test.shape)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "a7ptx3sTjkRd"
      },
      "outputs": [],
      "source": [
        "#Séparation des données en entrainement et test\n",
        "# from sklearn.model_selection import train_test_split\n",
        "\n",
        "# X_train, X_test, y_train, y_test = train_test_split(\n",
        "#       df_text,\n",
        "#       df_y,\n",
        "#       test_size=0.2,\n",
        "#      # stratify=df_y,\n",
        "#       random_state=42\n",
        "#     )\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "img_gen = ImageDataGenerator(validation_split=0.2,\n",
        "                             preprocessing_function = preprocess_input)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eErenZszjzmi"
      },
      "outputs": [],
      "source": [
        "#Passage en Numpy\n",
        "# X_train, y_train = X_train.values, y_train.values\n",
        "# X_test, y_test = X_test.values, y_test.values"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "f-N9Qvc1kZXQ"
      },
      "outputs": [],
      "source": [
        "#Conversion des labels de la target\n",
        "# from sklearn.preprocessing import LabelEncoder\n",
        "# le = LabelEncoder()\n",
        "# y_train_tr = le.fit_transform(y_train)\n",
        "# y_test_tr = le.transform(y_test)\n",
        "\n",
        "# print(np.unique(y_train), \"-->\", np.unique(y_test_tr))\n",
        "\n",
        "\n",
        "# Convert label from string to list of one element (required for the approach)\n",
        "labels_list = []\n",
        "for i in y_train['label']:\n",
        "    label = []\n",
        "    label.append(i)\n",
        "    labels_list.append(label)\n",
        "y_train['label'] = labels_list\n",
        "\n",
        "\n",
        "X_train['label'] = y_train['label']"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d72hzxhUXpoH"
      },
      "source": [
        "#### Modèle de texte"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uD4T2Q_EYCFu"
      },
      "source": [
        "#### Modèle des images"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "X_cVSoJZsmoa"
      },
      "outputs": [],
      "source": [
        "#Chemin du modèle  \n",
        "from tensorflow import keras\n",
        "from keras.layers import Dense, Flatten, Cropping2D, Conv2D, BatchNormalization, MaxPool2D, Dropout, GlobalAveragePooling2D, Activation, MaxPooling2D\n",
        "from keras.optimizers import Adam, SGD\n",
        "from keras.models import Model, Sequential\n",
        "from keras import backend as K\n",
        "from keras.applications.vgg16 import VGG16\n",
        "from keras.applications.vgg16 import preprocess_input\n",
        "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
        "from tensorflow.keras import callbacks\n",
        "from keras.callbacks import ModelCheckpoint, EarlyStopping\n",
        "\n",
        "\n",
        "MODEL_IMAGE_PATH = Path(PATH_MODELS, \"image\", MODEL_IMAGE_NAME)\n",
        "MODEL_IMAGE_PATH.mkdir(parents=True, exist_ok=True)\n",
        "\n",
        "\n",
        "#Génération des dataframes\n",
        "# df_train = pd.DataFrame(\n",
        "#             data=np.concatenate([X_train[:,0].reshape(-1, 1),\n",
        "#                                  y_train.reshape(-1, 1)],\n",
        "#                                 axis=1),\n",
        "#             columns=[\"links\", \"label\"])\n",
        "\n",
        "# df_test = pd.DataFrame(\n",
        "#             data=np.concatenate([X_test[:,0].reshape(-1, 1),\n",
        "#                                  y_test_tr.reshape(-1, 1)], axis=1),\n",
        "#             columns=[\"links\", \"label\"])\n",
        "        \n",
        "# df_train[\"label\"] = df_train[\"label\"].apply(lambda x: str(x))\n",
        "# df_test[\"label\"] = df_test[\"label\"].apply(lambda x: str(x))\n",
        "        \n",
        "       \n",
        "# #Creations des générateurs\n",
        "train_generator = img_gen.flow_from_dataframe(\n",
        "    X_train,\n",
        "    shuffle=True,\n",
        "    directory=PATH_IMAGES_TRAIN,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    class_mode='categorical',\n",
        "    target_size=TARGET_SHAPE[2],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='training'\n",
        ")\n",
        "\n",
        "test_generator = img_gen.flow_from_dataframe(\n",
        "    X_train,\n",
        "    shuffle=False,\n",
        "    directory=PATH_IMAGES_TRAIN,\n",
        "    x_col='filename',\n",
        "    y_col='label',\n",
        "    class_mode='categorical',\n",
        "    target_size=TARGET_SHAPE[2],\n",
        "    batch_size=BATCH_SIZE,\n",
        "    subset='validation'\n",
        ")\n",
        "  \n",
        "    \n",
        "# train_generator, test_generator = flow_generators(\n",
        "#             df_train, df_test,\n",
        "#             TARGET_SHAPE, BATCH_SIZE\n",
        "#         )\n",
        "\n",
        "\n",
        "if TRAIN_IMAGE:\n",
        "  \n",
        "  #Recuperation du modele\n",
        "  # model_image = image_tools.build_pipeline_model(\n",
        "  #               name=MODEL_IMAGE_NAME,\n",
        "  #               input_dim=TARGET_SHAPE,\n",
        "  #           )\n",
        "\n",
        "  unfreezed_layers = 0 #Nombre de couches a décongeler pour aplique le finetuning: Voir livre Deep Learning with python\n",
        "# Freezer les couches du VGG16\n",
        "  n_class = 27\n",
        "  base_model = VGG16(weights='imagenet', include_top=False, input_shape=TARGET_SHAPE) \n",
        "  # Freezer les couches du VGG16\n",
        "  for layer in base_model.layers[-unfreezed_layers:]: \n",
        "    layer.trainable = False\n",
        "\n",
        "  model = Sequential()\n",
        "  model.add(base_model) # Ajout du modèle VGG16\n",
        "  model.add(GlobalAveragePooling2D()) \n",
        "  model.add(Dense(1024, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(512, activation='relu'))\n",
        "  model.add(Dropout(0.2))\n",
        "  model.add(Dense(27, activation='softmax'))\n",
        "\n",
        "  # Callbacks\n",
        "  red_on_plateau = callbacks.ReduceLROnPlateau(monitor='val_accuracy',\n",
        "                                               patience=2,\n",
        "                                               factor=0.1,\n",
        "                                               verbose=1)       \n",
        "\n",
        "  early = EarlyStopping(monitor='val_accuracy', min_delta=0, patience=20, verbose=1, mode='auto')\n",
        "  \n",
        "  adam = Adam(learning_rate=0.005)\n",
        "\n",
        "  model.compile(\n",
        "      optimizer=adam, \n",
        "      loss=keras.losses.categorical_crossentropy, \n",
        "      metrics=['accuracy'])\n",
        "  \n",
        " \n",
        "  \n",
        "  #model.summary() \n",
        "  model_image = model\n",
        "     \n",
        "  #Lancement du Tensorboard\n",
        "  \n",
        "  %tensorboard --logdir $LOG_DIR_IMAGE\n",
        "  \n",
        "  #Entrainement et recuperation de l'historique\n",
        "  model_image_hist = model_image.fit(\n",
        "                train_generator,\n",
        "                epochs= EPOCHS_IMAGE,\n",
        "                #verbose=0,\n",
        "                steps_per_epoch= 50, #len(df_train)//BATCH_SIZE,\n",
        "                validation_data=test_generator,\n",
        "                validation_steps = 5, #len(df_test)//BATCH_SIZE,\n",
        "                callbacks=[\n",
        "                        model_tools.get_model_checkpoint(MODEL_IMAGE_PATH), \n",
        "                        model_tools.get_dashboard(LOG_DIR_IMAGE),\n",
        "                        model_tools.get_tqdm(),\n",
        "                        red_on_plateau,\n",
        "                        early\n",
        "                        ]\n",
        "            ) \n",
        "\n",
        "  if \"history\" in vars(model_image):\n",
        "                plt.plot(model_image_hist.history['accuracy'])\n",
        "                plt.plot(model_image_hist.history['val_accuracy'])\n",
        "                plt.title('model accuracy')\n",
        "                plt.ylabel('accuracy')\n",
        "                plt.xlabel('epoch')\n",
        "                plt.legend(['train', 'test'], loc='upper left')\n",
        "                \n",
        "                plt.savefig(Path(MODEL_IMAGE_PATH, 'history.jpg'))\n",
        "                plt.clf()\n",
        "#Sinon chargement d'un modele pour le texte\n",
        "else:\n",
        "  model_image = tf.keras.models.load_model(MODEL_IMAGE_PATH, compile=False)\n",
        "\n",
        "\n",
        "#Prediction\n",
        "y_image_preds = model_image.predict(test_generator)\n",
        "y_image_preds_class = np.argmax(y_image_preds, axis=1) if len(y_image_preds.shape)==2 else y_image_preds\n",
        "\n",
        "y_image_preds_class = le.inverse_transform(y_image_preds_class)\n",
        "\n",
        "crosstab = pd.crosstab(y_test, y_image_preds_class, rownames=[\"Real\"], colnames=[\"Predicted\"])\n",
        "print(classification_report_imbalanced(y_test, y_image_preds_class, zero_division=0))\n",
        "\n",
        "heat = graphs.heatmap(crosstab)\n",
        "plt.savefig(Path(MODEL_IMAGE_PATH, 'crosstab.jpg'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "K9jb2Cptl7oK"
      },
      "outputs": [],
      "source": [
        "model_image.summary()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "l5wNkj_IsOG7"
      },
      "outputs": [],
      "source": [
        "train_acc = model_image_hist.history['accuracy']\n",
        "val_acc = model_image_hist.history['val_accuracy']\n",
        "\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Accuracy')\n",
        "\n",
        "plt.plot(np.arange(1 , EPOCHS_IMAGE+1, 1),\n",
        "        model_image_hist.history['accuracy'],\n",
        "         label = 'Training Accuracy',\n",
        "         color = 'blue')\n",
        "\n",
        "plt.plot(np.arange(1 , EPOCHS_IMAGE+1, 1),\n",
        "         model_image_hist.history['val_accuracy'], \n",
        "         label = 'Validation Accuracy',\n",
        "         color = 'red')\n",
        "\n",
        "\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lqNGtgRjzDm3"
      },
      "outputs": [],
      "source": [
        "from sklearn.metrics import f1_score\n",
        "\n",
        "f1_score(test_generator.classes, y_image_preds.argmax(axis=1) , average=\"weighted\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EcOucUCRyqKx"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "v0CJ8Q1uiBtB"
      },
      "source": [
        "# Nouvelle section"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eKm6gPhbh_-5"
      },
      "source": [
        "# Nouvelle section"
      ]
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "private_outputs": true,
      "provenance": []
    },
    "gpuClass": "standard",
    "kernelspec": {
      "display_name": "env",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.9.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "b75a87c33401be6e4b50b30fb6526e3b0f1ee652121130951acb67c1afd19d74"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
